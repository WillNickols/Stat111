---
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{tcolorbox}
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \usepackage{wrapfig}
- \usepackage{amsmath}
urlcolor: blue
---

\pagestyle{fancy}
\fancyhf{}
\rhead{Will Nickols}
\lhead{Section 10}
\rfoot{Page \thepage}

# Announcements

\begin{wrapfigure}{r}{0.12\textwidth}
  \centering
    \vspace*{-1.3cm}
    \includegraphics[width=\linewidth]{section_qr_code.png}
\end{wrapfigure}

Make sure to sign in on the [google form](https://forms.gle/2PA9A94GpdmSDH2J9) (I send a list of which section questions are useful for which pset questions afterwards)

Pset 10 due Friday 4/21

```{r, echo=F, warning=F, message=F, cache=F}
list.of.packages <- c("ggplot2", "gridExtra", "reshape2", "dplyr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(ggplot2)
library(gridExtra)
library(reshape2)
library(dplyr)
```

# Cost effectiveness in global health

Significant work in economics and global health has gone into determining which healthcare interventions prevent the most suffering per dollar spent.  The metric of choice for these evaluations is the DALY, a disability adjusted life year.  When comparing interventions designed to save lives with those designed to improve lives, it is useful to have a metric that adjusts for the quality of life associated with various diseases and injuries, and the DALY attempts to do this.  For example, "severe motor impairment with blindness due to malaria" (being blind and unable to move around or sit up without help) has a weight of 0.512.  This means that avoiding a year of severe motor impairment with blindness is considered equivalent to avoiding 0.512 years of lost life.

The [Tufts Medical Center Cost-Effectiveness Analysis Registry](https://cear.tuftsmedicalcenter.org/registry/download) aggregates academic literature on healthcare interventions and standardizes the results to compare different interventions.  This literature is notoriously variable and unstandardized, so the specific metrics for each intervention might not be accurate, but the general trends should provide some insight.

```{r, fig.height=3, fig.width=7, fig.align='center', echo=F, cache=T}
set.seed(111)

CEA <- read.csv("data/CEA.csv")

# DALYs <= 0 are measuring something cost savings or are reported incorrectly
CEA <- CEA[!is.na(CEA$DALYinCurrentUSDollars) & CEA$DALYinCurrentUSDollars > 0,]
CEA$DalyPerThousand <- 1000/CEA$DALYinCurrentUSDollars

plot1 <- ggplot(CEA, aes(x=DalyPerThousand)) + 
  geom_histogram(bins = 100) + 
  theme_bw() + 
  xlab("DALYs averted per $1000") + 
  ylab("Interventions")

plot2 <- ggplot(CEA, aes(x=DalyPerThousand)) + 
  geom_histogram(bins = 100) + 
  theme_bw() + 
  xlab("DALYs averted per $1000") + 
  ylab("Interventions") + 
  scale_x_continuous(trans = 'log', breaks = 10^((-5):4)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

grid.arrange(plot1, plot2, ncol=2)
CEA$logDalyPerThousand <- log(CEA$DalyPerThousand)
```

1.  Let $Y_1,...,Y_n$ be the cost-effectivenesses of the $n$ interventions.  Suppose we are interested in the ratio of the cost effectiveness of the 95th percentile intervention to the median intervention (call this ratio $\theta$).  Assuming the data are i.i.d. from a Log-Normal distribution with parameters $\mu$ and $\sigma^2$, find the MLE $\hat{\theta}$.

\vspace{5 cm}

2. Find the asymptotic distribution for $\hat{\theta}$ and use this to approximate the standard error of the MLE.  Start from the exact distribution for $\hat{\sigma}^2$ and use the representation of a $\chi^2_n$ random variable as the sum of $n$ squared standard Normals to write a CLT statement.

\vspace{6 cm}

3. Explain how to approximate the standard error of $\hat{\theta}$ using a non-parametric bootstrap.

\vspace{2 cm}

4. Explain how to approximate the standard error of $\hat{\theta}$ using a non-parametric bootstrap.

\vspace{2 cm}

5. Explain how to approximate the standard error of $\tilde{\theta}=\hat{Q}(0.95)/\hat{Q}(0.5)$ using a non-parametric bootstrap (the quantile is on the original scale).

\vspace{2 cm}

6. Explain how to approximate the standard error of $\tilde{\theta}$ with a parametric bootstrap.

\vspace{2 cm}

7. Compare the standard errors from 2-6.

```{r, cache=T}
# First two shown as an example
n <- nrow(CEA)
  
# 2. Theta hat approximate SE
se_2 <- sqrt(2) * var(CEA$logDalyPerThousand) * qnorm(0.95) / 
  (2 * sd(CEA$logDalyPerThousand)) * 
  exp(sd(CEA$logDalyPerThousand) * qnorm(0.95)) / (sqrt(n))

# 3. Theta hat non-parametric SE
nboot <- 10^4
one_boot <- function() {
  samples <- sample(CEA$logDalyPerThousand, n, replace = T)
  return(exp(sqrt(var(samples) * (n - 1)/(n)) * qnorm(0.95)))
}
boots <- replicate(nboot, one_boot())
se_3 <- sd(boots)
```

```{r, cache=T, echo=F}
# 4. Theta hat parametric SE
mu_hat <- mean(CEA$logDalyPerThousand)
sigma_sq_hat <- var(CEA$logDalyPerThousand) * (n - 1) / n
nboot <- 10^4
one_boot <- function() {
  samples <- exp(rnorm(n, mu_hat, sqrt(sigma_sq_hat)))
  return(exp(sqrt(var(log(samples)) * (n - 1)/(n)) * qnorm(0.95)))
}
boots <- replicate(nboot, one_boot())
se_4 <- sd(boots)

# 5. Theta tilde non-parametric bootstrap
one_boot <- function() {
  samples <- sample(CEA$DalyPerThousand, n, replace = T)
  return(quantile(samples, 0.95) / quantile(samples, 0.5))
}
boots <- replicate(nboot, one_boot())
se_5 <- sd(boots)

# 6. Theta tilde parametric bootstrap
one_boot <- function() {
  samples <- exp(rnorm(n, mu_hat, sqrt(sigma_sq_hat)))
  return(quantile(samples, 0.95) / quantile(samples, 0.5))
}
boots <- replicate(nboot, one_boot())
se_6 <- sd(boots)

round(c("Theta hat" = exp(sqrt(var(CEA$logDalyPerThousand) * 
                                 (nrow(CEA) - 1)/(nrow(CEA))) * qnorm(0.95)), 
        "Theta tilde" = unname(quantile(CEA$DalyPerThousand, 0.95)) / 
          unname(quantile(CEA$DalyPerThousand, 0.5))), 3)
df <- data.frame(round(c("Theta hat SE approximate" = se_2, 
                         "Theta hat SE non-parametric bootstrapped" = se_3, 
                         "Theta hat SE parametric bootstrap" = se_4,
                         "Theta tilde Non-parametric bootstrap" = se_5, 
                         "Theta tilde parametric bootstrap" = se_6), 3))

colnames(df) <- c("")
knitr::kable(df)
```

\vspace{2 cm}

8. Explain how to construct an approximate 95\% bootstrap confidence interval for $\theta$ with the percentile method on $\tilde{\theta}$.

\vspace{2 cm}

9. Explain how to construct an approximate 95\% bootstrap confidence interval for $\theta$ with a Normal approximation and a bootstrap standard error for $\tilde{\theta}$.  Use the scale with better asymptotic properties and then convert the interval if necessary.

\vspace{3 cm}

10. Compare the bootstrap intervals from 7 and 8 including both scales for the Normal approximation.

```{r, cache=T}
nboot <- 10^4
one_boot <- function() {
  samples <- sample(CEA$DalyPerThousand, n, replace = T)
  return(quantile(samples, 0.95) / quantile(samples, 0.5))
}
boots <- replicate(nboot, one_boot())
perc_method <- quantile(boots, c(0.025, 0.975))

norm_approx_1 <- c(quantile(CEA$DalyPerThousand, 0.95) / 
                     quantile(CEA$DalyPerThousand, 0.5) - sd(boots) * qnorm(0.975),
  quantile(CEA$DalyPerThousand, 0.95) / quantile(CEA$DalyPerThousand, 0.5) + 
    sd(boots) * qnorm(0.975))

one_boot <- function() {
  samples <- sample(CEA$logDalyPerThousand, n, replace = T)
  return(quantile(samples, 0.95) - quantile(samples, 0.5))
}
boots <- replicate(nboot, one_boot())
norm_approx_2 <- exp(c(quantile(CEA$logDalyPerThousand, 0.95) - 
                         quantile(CEA$logDalyPerThousand, 0.5) - sd(boots) * qnorm(0.975),
  quantile(CEA$logDalyPerThousand, 0.95) - quantile(CEA$logDalyPerThousand, 0.5) + 
    sd(boots) * qnorm(0.975)))

df <- data.frame(round(rbind(perc_method, norm_approx_1, norm_approx_2), 2))
rownames(df) <- c("Percentile method", "Normal approximation original scale", 
                  "Normal approximation log scale")
colnames(df) <- c("Lower", "Upper")
knitr::kable(df)
```

\vspace{1 cm}

One thing we might be interested in is how cost-effectiveness differs by country.  As in week 8, we can perform a Bayesian readjustment (Normal this time) to account for the number of studies in each country.  The table below shows the posterior means for intervention cost-effectiveness in the top and bottom countries.

```{r, fig.height=4, fig.width=7, fig.align='center', echo=F, cache=T}
aggregated_countries <- do.call(data.frame, 
                                (aggregate(logDalyPerThousand ~ Country, CEA, 
                                           FUN = function(x) c(mu = mean(x), sd = sd(x) ) )))
country_count <- data.frame(table(CEA$Country))
colnames(country_count) <- c("Country", "Studies")
aggregated_countries <- left_join(aggregated_countries, country_count, by=c("Country"))
colnames(aggregated_countries) <- c("Country", "mu", "sd", "Studies")
grand_mean <- mean(CEA$logDalyPerThousand)
grand_var <- var(CEA$logDalyPerThousand)

aggregated_countries$adjustedDalyPerThousand <- 1 / (1 / grand_var + aggregated_countries$Studies / 
                                                       aggregated_countries$sd) * 
  (grand_mean / grand_var + aggregated_countries$mu * aggregated_countries$Studies / aggregated_countries$sd)

high_val <- cbind("County" = aggregated_countries$Country[order(aggregated_countries$adjustedDalyPerThousand, decreasing = T)[1:10]],
                "Adjusted DALYs averted per $1000" = round(exp(aggregated_countries$adjustedDalyPerThousand[order(aggregated_countries$adjustedDalyPerThousand, decreasing = T)[1:10]]), 2),
                "Studies" = aggregated_countries$Studies[order(aggregated_countries$adjustedDalyPerThousand, decreasing = T)[1:10]])

knitr::kable(high_val)

low_val <- cbind("County" = aggregated_countries$Country[order(aggregated_countries$adjustedDalyPerThousand, decreasing = F)[1:10]],
                "Adjusted DALYs averted per $1000" = round(exp(aggregated_countries$adjustedDalyPerThousand[order(aggregated_countries$adjustedDalyPerThousand, decreasing = F)[1:10]]), 3),
                "Studies" = aggregated_countries$Studies[order(aggregated_countries$adjustedDalyPerThousand, decreasing = F)[1:10]])

knitr::kable(low_val)
```

11. [The World Bank classifies](https://datahelpdesk.worldbank.org/knowledgebase/articles/906519) countries with gross national income per capita below \$1085 as low-income and countries with GNI per capitas above \$13205 as high-income.  Let $\mu_1$ and $\mu_2$ be the true mean cost-effectiveness of interventions in low and high income countries respectively.  Perform a two-sample $t$-test for $H_0:\mu_1=\mu_2$ vs $H_a:\mu_1\neq \mu_2$.

```{r, cache=T}
income <- read.csv("data/income.csv")[,c(1,2)]
CEA_with_income <- inner_join(CEA, income, by=c("Country"))
high_income <- CEA_with_income$DalyPerThousand[CEA_with_income$Income == "High"]
low_income <- CEA_with_income$DalyPerThousand[CEA_with_income$Income == "Low"]
# TODO: Run t test
```

\vspace{1 cm}

12. Perform a permutation test for whether the distributions of cost-effectiveness of interventions are different between country income groups.  Use the absolute difference in sample means as the test statistic.

```{r, fig.height=3, fig.width=4, fig.align='center', cache=T, eval=F}
nperm <- 10^5

run_perm <- function(x, y) {
  # TODO: Create permutation
}

perms <- replicate(nperm, 
                   run_perm(CEA_with_income$DalyPerThousand[CEA_with_income$Income == "High"],
                          CEA_with_income$DalyPerThousand[CEA_with_income$Income == "Low"]))

mean(perms > abs(mean(CEA_with_income$DalyPerThousand[CEA_with_income$Income == "High"]) - 
       mean(CEA_with_income$DalyPerThousand[CEA_with_income$Income == "Low"])))
```

```{r, fig.height=3, fig.width=4, fig.align='center', cache=T, eval=F, echo=F}
ggplot(data.frame(x=perms), aes(x=x)) + 
  geom_density() + 
  theme_bw() + 
  geom_vline(xintercept = 
               abs(mean(CEA_with_income$DalyPerThousand[CEA_with_income$Income == "High"]) - 
       mean(CEA_with_income$DalyPerThousand[CEA_with_income$Income == "Low"])), col="red") + 
  ylab("Bootstrap density") + 
  xlab("Absolute difference in means")
```

\vspace{1 cm}

13. Compare the assumptions and conclusions for the test in 10 and the test in 11.  The following plot may be helpful.

```{r, fig.height=3, fig.width=4, fig.align='center', cache=T, echo=F}
ggplot(CEA_with_income, aes(x=DalyPerThousand, col=Income)) + 
  geom_density() + 
  scale_x_continuous(trans = 'log', breaks = 10^((-5):4)) + 
  ylab("Density") + 
  xlab("DALYs averted per $1000") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

\vspace{7 cm}

# Feedback

As part of my continual effort to improve my teaching, please take a moment to [provide some feedback](https://forms.gle/QyKkjnprbZiT3NeW7) on section this semester.

\centering
\includegraphics[width=0.3\linewidth]{feedback_qr.png}















